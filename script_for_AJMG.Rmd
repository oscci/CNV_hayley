---
title: "script_for_AJMG"
author: "DVM Bishop + P Thompson"
date: "18/11/2019"
updated: "01/12/2019"
output: html_document
---

Document based on pre-registered analysis by Mountford et al:
https://osf.io/u2j97
Updated 1st Dec 2019 to add comparison of synthetic data to real data.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# many of these functions copied from CNV_for_protocol

require(synthpop) #used to create synthetic dataset
require(tidyverse)
require(stringr)
require(plyr)
require(yarrr)
require(knitr)
library(Hmisc) #for correlation matrix
library(ggplot2)
library(gridExtra)
library(ggpubr)
library(scales)
require(sandwich)
require(msm)
require(lemon) #for glegend
require(MASS)
require(simglm)
require(conflicted) #flags up conflicted functions
require(sandwich)
library(coin)
library(psych)
```

## Read and merge files

Github repository is CNV_Hayley

R project is CNV_Hayley.Rproj on deevybee_repo

Original protocol is CNV_for_protocol.rmd from Jun 16 2018

Manuscript draft is with oscci manuscripts in folder hayley cnv, as Trisomy_CNV_AJMG_v2_DB 

For this OSF version we will read the data from a pre-merged file.
However, the original chunk for doing the merging is retained here, but not run.
(To run it, need to set readoriginal <- 1 at the top of the chunk).

Further information that is only key if you need to set readoriginal to 1:
Data on CNVs now in same folder as R project; original xls file from Dianne, with parental concern variable, is saved as 2 worksheets in csv â€“ one for autosomes and one for X chromosome
all_samples_results_parco.csv
all_samples_results_Xchrom.csv

These need to have name codes changed to match our codes by stripping off DB and making other minor modifications.

Remember to set working directory to source file location

NB famsplangconc coded as 1 if any concern about speech/language in either twin. (Concern may be about the co-twin to the proband) - some of these were coded N/A in Di's file - have updated these manually.


```{r readfiles}
readoriginal <- 1 
  #set to 0 to read true data (cnvpheno.csv)
  #set to 1 if you want to run chunk to recreate merged cnvpheno file from original files
  #set to 2 to read synthetic data (cnv_syn.csv)
makesyn <- 1 #set to 1 to create a synthetic dataset from original data (see end of chunk)

if (readoriginal==1){
cnvdat<-read.csv('all_samples_results_parco_corrected.csv',stringsAsFactors=FALSE)
cnvdatx<-read.csv('all_samples_results_Xchrom.csv',stringsAsFactors=FALSE)

identical(cnvdat$id,cnvdatx$id) #OK - original files were not identical- found mismatch

genderdat<-read.csv('TwinsData_gender.csv')
phenodat<-read.csv('unblinded_pheno_sct_twin.csv',stringsAsFactors=FALSE)
#This file was created using 'geno_pheno_analysis_190215.Rmd' - i.e. main script for Newbury et al paper. In that script, IDs are blinded, but here we need to match up with CNV data, so retain the codes.

#need to strip out correct ID from the cnv files
#first of all remove _rpt from end of name
#also remove DB from start
#using cnvdatx as this seems more accurate, but ultimately should agree with cnvdat



for (i in 1:nrow(cnvdatx)){
  cnvdatx$id[i] <-  str_replace(cnvdatx$id[i],"_rpt", "")
  cnvdatx$id[i] <-  str_replace(cnvdatx$id[i],"DB", "")
    cnvdat$id[i] <-  str_replace(cnvdat$id[i],"_rpt", "")
  cnvdat$id[i] <-  str_replace(cnvdat$id[i],"DB", "")
}

#for SCTs, just retain first 3 digits
myrows<-which(cnvdatx$Group != 'twin')

cnvdatx$id[myrows]<-str_sub(cnvdatx$id[myrows],1,3)
cnvdat$id[myrows]<-str_sub(cnvdatx$id[myrows],1,3)
#NB these ids are characters, so need to alter phenodat,where id is numeric
#Need to add leading zeroes, so, e.g. 1 becomes 001

phenodat$id<-as.character(phenodat$record_id)
w<-which(as.numeric(phenodat$record_id)<10)
phenodat$id[w]<-paste0('0',phenodat$id[w])
w<-which(as.numeric(phenodat$record_id)<100)
phenodat$id[w]<-paste0('0',phenodat$id[w])

#order all files by id
genderdat <- genderdat[order(genderdat$record_id),] 
phenodat <- phenodat[order(phenodat$id),] 
cnvdat <- cnvdat[order(cnvdat$id),] 
cnvdatx <- cnvdatx[order(cnvdatx$id),] 
#align files and bolt together

#Just check we do have same cases in same rows
for(i in 1:nrow(cnvdat)){
  if(cnvdat$id[i] != cnvdatx$id[i]){
    print(cnvdat$id[i])
  }
  }



w<-which(phenodat$id %in% cnvdatx$id)

cnvpheno<-cbind(phenodat[w,2:44],cnvdat[,2:11],cnvdatx[,2:8])

cnvpheno$female<-0
w4<-which(cnvpheno$trisomy==1)
cnvpheno$female[w4]<-1

w3<-which(cnvpheno$Group=='twin')
w2<-which(genderdat$record_id %in% cnvpheno$id) #twins only!

cnvpheno$female[w3]<-genderdat$female[w2] #twins who are in cnvpheno assigned gender from genderdat

cnvpheno$groupfem<-paste0(cnvpheno$Group,cnvpheno$female)

#Do some renaming of cols
for (i in 54:60){
  colnames(cnvpheno)[i]<-paste0(colnames(cnvpheno)[i],'X')
}
cnvpheno$is.trisomy <-1
w<-which(cnvpheno$Group=='twin')
cnvpheno$is.trisomy[w]<-0 

#code bias group
cnvpheno$bias<-cnvpheno$famsplangconc #default from twin code for family bias

w<-which(cnvpheno$Group !='twin')
cnvpheno$bias[w]<-0 #default no bias for trisomies
w<-c(which(cnvpheno$why_tested==2),which(cnvpheno$why_tested==3))
cnvpheno$bias[w]<-1

write.csv(cnvpheno,'cnvpheno.csv',row.names=FALSE) #saved copy of file
}
```

```{r makesynthetic}
if(makesyn==1){
#now create synthetic dataset to preserve confidentiality
  # Do this in blocks to preserve number counts
  set.seed(2) #arbitrary seed to ensure synthetic data the same each time

  r <- 0
  for (t in 0:1){
    for (b in 0:1){
      r<-r+1
      w1<- which(cnvpheno$is.trisomy==t)
      w2<- which(cnvpheno$bias==b)
      w <-intersect(w1,w2)
      synobj<-syn(cnvpheno[w,c(62,64,42,44:50,55:60)]) #object including synth dataset - NB do not include is.trisomy as this predictable from groupfem.
  #Put groupfem and bias as first variables - will be used as predictors
      tempsyn <- synobj$syn #synthetic dataset
      if (r==1){
        mysyn<-tempsyn
      }
      if (r>1){
        mysyn<-rbind(mysyn,tempsyn)
      }
    }
  }
mysyn$is.trisomy <-1
w<-c(which(mysyn$groupfem=='twin0'),which(mysyn$groupfem=='twin1'))
mysyn$is.trisomy[w]<-0
write.csv(mysyn,'cnv_syn_OSF.csv',row.names=FALSE)
}
```

```{r comparefiles}
#compare combined synthetic data with original
synobj$syn<-mysyn #substitute combined file in the object 
synthcom <- synthpop::compare(
  synobj,
  cnvpheno,
  vars = c("global_neurodev", "sum_pLi",
            "total_cnvs" ,   "total_Kbp"),
  print.coef = TRUE,
    stat = "counts",
  nrow=2, #nrow for plot
  ncol=2, #ncol for plot
  cols = c("#62B6CB", "#1B4965")
) # Visual comparison of original and synthetic datasets

synthcom$tables # Show comparison tables
synthcom$plots

cnvpheno2 <- cnvpheno[,c(62:64,42,44:50,55:60)]
 multi.compare(synobj, cnvpheno2,
                         var = "bias", by = "global_neurodev",binwidth=2)
 multi.compare(synobj, cnvpheno2,
                         var = "is.trisomy", by = "global_neurodev",binwidth=2)
```

We now have a file with the phenotype and genotype data together.  
First thing that is needed is Table 1, showing Ns in relation to ascertainment bias.

```{r table1}


if(readoriginal==0){
  cnvpheno <- read.csv('cnvpheno.csv',stringsAsFactors=FALSE)
}
if(readoriginal==2 ){ #read synthesised data}
  cnvpheno <- read.csv('cnv_syn.csv',stringsAsFactors=FALSE)
}
mytab<- table(cnvpheno$groupfem,cnvpheno$bias)
mytab

# Added March 2020
# Add binary code to denote those with pathogenic cnvs
## TEXT SAYS 7 in TWINS - I can only find 6 as below
pathocase <- c('639A','664B','668B','679A','869B','874A',
               '244','257','085','134','355','066','339','131','348')
w<-which(cnvdat$id %in% pathocase)
cnvdat$id[w]
cnvdat$path<-0
cnvdat$path[w]<-1
```

The derivation of the global neurodevelopmental index is now provided in the paper in Table 2.
(In this version we use original scores, so high score represents poor functioning. 




```{r for.Fig1, echo=FALSE}
#-----------------------------------------------------------------------------#


# Scatter plot with marginal histograms 
# Have taken log for kBp to aid visualisation
# Used colour to depict twin/SCT and fill to depict low bias

# Create factor variables for group and bias
cnvpheno$trisomy<-factor(cnvpheno$is.trisomy)
levels(cnvpheno$trisomy) <- c('Comparison','Trisomy')

cnvpheno$bias_fac<-as.factor(cnvpheno$bias)
shapelist<-c(19,1)  
#This variable allows mapping of shape and fill as follows:
# bias = unfilled circle
# no Bias = filled circle

levels(cnvpheno$bias_fac) <- c('Low bias' ,'High Bias')
cnvpheno$jitter_cnv<-jitter(cnvpheno$total_cnvs)+.2 #add .2 to avoid negative value
p1 <- ggplot(cnvpheno,aes(y=log(total_Kbp+1),x=jitter_cnv,colour=trisomy,shape=bias_fac))+
  scale_shape_manual(values=shapelist)+
   scale_color_manual(values=c('gray21','red'))+
  geom_point()+
  scale_x_continuous(expand=c(0.02,0)) +
  scale_y_continuous(expand=c(0.02,0)) +
 labs(x = "N CNVs",y="Total CNV span (log Kb)")+
  theme_bw() + guides(row = guide_legend(nrow=2)) +
  theme(legend.position=c(1,1.25),plot.margin=unit(c(1,1,1,1),"points"),legend.title = element_blank(),legend.text = element_text(size = 8),axis.title = element_text(size = 10),legend.box = "horizontal",
        legend.background = element_rect(fill="grey",colour = "black"))

theme0 <- function(...) theme( legend.position = "none",
                               panel.background = element_blank(),
                               panel.grid.major = element_blank(),
                               panel.grid.minor = element_blank(),
                               panel.margin = unit(0,"null"),
                               axis.ticks = element_blank(),
                               axis.text.x = element_blank(),
                               axis.text.y = element_blank(),
                               axis.title.x = element_blank(),
                               axis.title.y = element_blank(),
                               axis.ticks.length = unit(0,"null"),
                               axis.ticks.margin = unit(0,"null"),
                               panel.border=element_rect(color=NA),...)

p2 <- ggplot(cnvpheno,aes(x=total_cnvs,colour=factor(trisomy),fill=factor(trisomy))) + 
  geom_density(alpha=0.5) + 
  scale_color_manual(values=c('gray21','red'))+
  scale_fill_manual(values=c('gray21','red'))+
  scale_x_continuous(breaks=NULL,expand=c(0.00,0)) +
  scale_y_continuous(breaks=NULL,expand=c(0.00,0)) +
  theme_bw() +
  theme0(plot.margin = unit(c(0,0,0,2),"lines")) 

p3 <- ggplot(cnvpheno,aes(x=log(total_Kbp+1),colour=factor(trisomy),fill=factor(trisomy))) + 
  geom_density(alpha=0.5) + 
  scale_color_manual(values=c('gray21','red'))+
   scale_fill_manual(values=c('gray21','red'))+
  coord_flip()  + 
  scale_x_continuous(labels = NULL,breaks=NULL,expand=c(0.02,0)) +
  scale_y_continuous(labels = NULL,breaks=NULL,expand=c(0.00,0)) +
  theme_bw() +
  theme0(plot.margin = unit(c(0,0,1.75,0),"lines"))

#assemble the 3 plots in a grid

 g1<-grid.arrange(arrangeGrob(p2,ncol=2,widths=c(3,1)),
             arrangeGrob(p1,p3,ncol=2,widths=c(3,1)),
             heights=c(1,3))
g1
 #ggsave preserves appearance of plot. 
ggsave("CNV_fig1.png",plot=g1,device = 'png',dpi = 600,width=4.5,height=4,units = 'in')

# The figure we've just created is displayed in the Markdown document

##############################################################################
```

![Figure 1](CNV_fig1.png)

```{r for.Fig2, echo=FALSE}
#-----------------------------------------------------------------------------#

# Figure 2 shows PLI score with global neurodev scale
# Otherwise same as figure 1
# Scatter plot with marginal histograms 
# Used colour to depict twin/SCT and fill to depict bias - use settings from fig 1

cnvpheno$neurodev_jittered <- jitter(cnvpheno$global_neurodev)+.2
p1 <- ggplot(cnvpheno,aes(x=sum_pLi,y=neurodev_jittered,colour=trisomy,shape=bias_fac))+
  scale_shape_manual(values=shapelist)+
   scale_color_manual(values=c('gray21','red'))+
  geom_point()+
  scale_x_continuous(expand=c(0.02,0)) +
  scale_y_continuous(expand=c(0.02,0)) +
 labs(x = "Total pLI (all CNVs)",y="Global neurodev. impairment")+
  theme_bw() + guides(row = guide_legend(nrow=2)) +
  theme(legend.position=c(1,1.25),plot.margin=unit(c(1,1,1,1),"points"),legend.title = element_blank(),legend.text = element_text(size = 8),axis.title = element_text(size = 10),legend.box = "horizontal",
        legend.background = element_rect(fill="grey",colour = "black"))

theme0 <- function(...) theme( legend.position = "none",
                               panel.background = element_blank(),
                               panel.grid.major = element_blank(),
                               panel.grid.minor = element_blank(),
                               panel.margin = unit(0,"null"),
                               axis.ticks = element_blank(),
                               axis.text.x = element_blank(),
                               axis.text.y = element_blank(),
                               axis.title.x = element_blank(),
                               axis.title.y = element_blank(),
                               axis.ticks.length = unit(0,"null"),
                               axis.ticks.margin = unit(0,"null"),
                               panel.border=element_rect(color=NA),...)

p2 <- ggplot(cnvpheno,aes(x=sum_pLi,colour=factor(trisomy),fill=factor(trisomy))) + 
  geom_density(alpha=0.5) + 
  scale_color_manual(values=c('gray21','red'))+
  scale_fill_manual(values=c('gray21','red'))+
  scale_x_continuous(breaks=NULL,expand=c(0.00,0)) +
  scale_y_continuous(breaks=NULL,expand=c(0.00,0)) +
  theme_bw() +
  theme0(plot.margin = unit(c(0,0,0,2),"lines")) 

p3 <- ggplot(cnvpheno,aes(x=global_neurodev,colour=factor(trisomy),fill=factor(trisomy))) + 
  geom_density(alpha=0.5) + 
  scale_color_manual(values=c('gray21','red'))+
   scale_fill_manual(values=c('gray21','red'))+
  coord_flip()  + 
  scale_x_continuous(labels = NULL,breaks=NULL,expand=c(0.02,0)) +
  scale_y_continuous(labels = NULL,breaks=NULL,expand=c(0.00,0)) +
  theme_bw() +
  theme0(plot.margin = unit(c(0,0,1.75,0),"lines"))



g2<- grid.arrange(arrangeGrob(p2,ncol=2,widths=c(3,1)),
             arrangeGrob(p1,p3,ncol=2,widths=c(3,1)),
             heights=c(1,3))

ggsave("CNV_fig2.png",plot=g2,device = 'png',dpi = 600,width=4.5,height=4,units = 'in')



##############################################################################
```
![Figure 2](CNV_fig2.png)



Next we consider how well the different measures differentiate between the groups. Because the data is non-normal, a Wilcoxon rank sum test is used. In a preliminary analysis, we analyse each dependent measure separately.

```{r comparegp,echo=FALSE}
##############################################################################

#Multiple testing: Wilcoxon sum rank test, one-tailed
dowilcox <- function(mydf){
BF_correct_alpha<-0.05/3
w1<-wilcox.test(total_cnvs~is.trisomy,data=mydf,alternative=c("less"),conf.int=TRUE)
w2<-wilcox.test(total_Kbp~is.trisomy,data=mydf,alternative=c("less"),conf.int=TRUE)
w3<-wilcox.test(sum_pLi~is.trisomy,data=mydf,alternative=c("less"),conf.int=TRUE)


#Corrections for multiple testing

# Given correlations between the CNV measures, the Benjamini-Yekutieli (BY) correction is applied. We see that the pattern of significance among the tests remains unchanged.

##
pvals<-round(c(w1$p.value,w2$p.value,w3$p.value),3)
BY = p.adjust(pvals, "BY")
res = cbind(pvals, BY=round(BY, 3))
colnames(res)<-c("Uncorrected","Benjamini-Y")
rownames(res)<-c('Total CNVs','Total Kbp',"sum pLi")
return(res)}

```

Hayley had done analysis using permutation analysis in PLINK. We can achieve the same results in R. N.B. 
This was not the pre-registered analysis, though it could be argued that it is a reasonable one to do. The results do differ from Wilcoxon - we think this is to do with how the different methods handle ties.

Here is a function to do that

```{r permtest}
#Multiple testing: permutation test, one-tailed
doperm <- function(mydf){
BF_correct_alpha<-0.05/3

p1<-coin::pvalue(oneway_test(total_cnvs~is.trisomy,data=mydf, alternative="less", 
                   distribution=approximate(nresample=9999)))
p2<-coin::pvalue(oneway_test(total_Kbp~is.trisomy,data=mydf, alternative="less", 
                   distribution=approximate(nresample=9999)))
p3<-coin::pvalue(oneway_test(sum_pLi~is.trisomy,data=mydf, alternative="less", 
                   distribution=approximate(nresample=9999)))

pvals<-round(c(p1[1],p2[1],p3[1]),3)
BY = p.adjust(pvals, "BY")
res = cbind(pvals, BY=round(BY, 3))
colnames(res)<-c("Uncorrected","Benjamini-Y")
rownames(res)<-c('Total CNVs','Total Kbp',"sum pLi")
return(res)}

```

```{r makeresultstabs}

cnvpheno$is.trisomy<-as.factor(cnvpheno$is.trisomy)
# Divide data into 2 sets; with and without bias
w<-which(cnvpheno$bias==1)
bias.set<-cnvpheno[w,]
nobias.set<-cnvpheno[-w,]

resw1 <-dowilcox(cnvpheno)
knitr::kable(resw1, caption='Wilcoxon: All cases')

resw2 <-dowilcox(nobias.set)
knitr::kable(resw2, caption='Wilcoxon: Low bias cases')

resp1<-doperm(cnvpheno)
knitr::kable(resp1, caption='Permutation: All cases')

resp2<-doperm(nobias.set)
knitr::kable(resp2, caption='Permutation: Low bias cases')

print('All cases')
by_group<-cnvpheno %>% dplyr::group_by(is.trisomy)
groupmeans<-dplyr::summarise(by_group,
  mean_cnvs = round(mean(total_cnvs),2),
   sd_cnvs = round(sd(total_cnvs),2),
    mean_Kbp = round(mean(total_Kbp),1),
   sd_Kbp = round(sd(total_Kbp),1),
  mean_pLi = round(mean(sum_pLi),3),
  sd_pLi = round(sd(sum_pLi),3)
)
groupmeans

print('Low Bias')
by_group2<-nobias.set %>% dplyr::group_by(is.trisomy)
groupmeans2<-dplyr::summarise(by_group2,
  mean_cnvs = round(mean(total_cnvs),2),
   sd_cnvs = round(sd(total_cnvs),2),
    mean_Kbp = round(mean(total_Kbp),1),
   sd_Kbp = round(sd(total_Kbp),1),
  mean_pLi = round(mean(sum_pLi),3),
  sd_pLi = round(sd(sum_pLi),3)
)
groupmeans2

```

```{r makemaintable}
maintab <- data.frame(matrix(NA,nrow=9,ncol=6))
colnames(maintab)<- c('Measure','SCT','Comparison','.','p-values','..')
maintab[,1]<-c('N Whole sample','CNV per individual','CNV total span (Kb)','Total pLI score','.','N low bias subset','CNV per individual','CNV total span (Kb)','Total pLI score')

#can take Ns from original Table 1 (mytab)
Nsct<-sum(mytab[3:5,1:2])
Ntwin<-sum(mytab[1:2,1:2])
Nsct.x<-sum(mytab[3:5,1])
Ntwin.x<-sum(mytab[1:2,1])

maintab[1,2]<-Nsct
maintab[1,3]<-Ntwin
maintab[6,2]<-Nsct.x
maintab[6,3]<-Ntwin.x

maintab[1,4]<-'Wilcoxon'
maintab[1,5]<-'Permutation'
maintab[1,6]<-'BY corrected'

maintab[2,2]<-paste0(groupmeans[2,2],' (',groupmeans[2,3],')')
maintab[2,3]<-paste0(groupmeans[1,2],' (',groupmeans[1,3],')')

maintab[3,2]<-paste0(groupmeans[2,4],' (',groupmeans[2,5],')')
maintab[3,3]<-paste0(groupmeans[1,4],' (',groupmeans[1,5],')')

maintab[4,2]<-paste0(groupmeans[2,6],' (',groupmeans[2,7],')')
maintab[4,3]<-paste0(groupmeans[1,6],' (',groupmeans[1,7],')')

maintab[7,2]<-paste0(groupmeans2[2,2],' (',groupmeans2[2,3],')')
maintab[7,3]<-paste0(groupmeans2[1,2],' (',groupmeans2[1,3],')')

maintab[8,2]<-paste0(groupmeans2[2,4],' (',groupmeans2[2,5],')')
maintab[8,3]<-paste0(groupmeans2[1,4],' (',groupmeans2[1,5],')')

maintab[9,2]<-paste0(groupmeans2[2,6],' (',groupmeans2[2,7],')')
maintab[9,3]<-paste0(groupmeans2[1,6],' (',groupmeans2[1,7],')')

maintab[2:4,4]<-resw1[1:3,1]
maintab[7:9,4]<-resw2[1:3,1]
maintab[2:4,5:6]<-resp1[1:3,1:2]
maintab[7:9,5:6]<-resp2[1:3,1:2]

write.csv(maintab,'Table3.csv',row.names=FALSE)

#This table can be opened in Word.
# Needs editing (change comma to tab, remove quotes and NA, but can then do convert text to table, and minor formatting)
```


## Phenotype analysis
We have three possible phenotypes that were used by Newbury et al (2018). We decided *a priori* that the measure of global neurodevelopmental impairment is optimal, because previous research on CNVs implicates more severe conditions such as ASD and intellectual disability, which are captured by this measure.




## Poisson regression
Poisson regression is the optimal method, as the dependent variable is a count. This will naturally allow for the lower bound of zero.

Reference for analysis: https://stats.idre.ucla.edu/r/dae/poisson-regression/
```{r poisson, echo=TRUE}
#-----------------------------------------------------------------------------#
summary(m1 <- glm(global_neurodev ~ sum_pLi + is.trisomy + sum_pLi:is.trisomy, family="poisson", data=cnvpheno))

#check the assumption that mean and variance ar roughly equal. If not, we can use robust estimates. I think this will make little difference in our case but included for completeness.

cov.m1 <- vcovHC(m1, type="HC0")
std.err <- sqrt(diag(cov.m1))
r.est <- cbind(Estimate= coef(m1), "Robust SE" = std.err,
               "Pr(>|z|)" = 2 * pnorm(abs(coef(m1)/std.err), lower.tail=FALSE),
               LL = coef(m1) - 1.96 * std.err,
               UL = coef(m1) + 1.96 * std.err)

r.est

#test the effect of dropping is.trisomy. We anticipate that this will be impair model fit.
m2 <- update(m1, . ~ . - is.trisomy)
## test model differences with chi square test
anova(m2, m1, test="Chisq")

#-----------------------------------------------------------------------------#
```

## Exploratory analyses requested by reviewers
Reviewers requested (a) more descriptive data in table 1; (b) analysis stratified by trisomy type (table3); (b) analysis of alternative phenotypes (table4)

```{r moretable1}
require(psych)
#Reading in updated version of cnvpheno which included ethnicity
cnvpheno<- read.csv('cnvpheno2.csv',stringsAsFactors=FALSE)
#Create 5 categories
cnvpheno$allgroup<-as.factor(cnvpheno$groupfem)
levels(cnvpheno$allgroup)<-c('XY','XX','XXX','XXY','XYY')
#report for all 5 possible groups
table1a <- data.frame(matrix(NA,nrow=6,ncol=6))
colnames(table1a)<-c('Variable','XY','XX','XXX','XXY','XYY')
myN <- table(cnvpheno$allgroup)
table1a[1,]<-c('N',myN)
#Add age in row 2
myaggmean <-aggregate(cnvpheno$age_at_test,by=list(cnvpheno$allgroup),FUN=mean,na.rm=TRUE)
myaggsd <-aggregate(cnvpheno$age_at_test,by=list(cnvpheno$allgroup),FUN=sd,na.rm=TRUE)
table1a[2,1]<-'Mean (SD) age (mo)'
for (i in 1:5){
table1a[2,(i+1)] <-paste0(round(myaggmean[i,2],1),' (',round(myaggsd[i,2],1),')')
}
#Add %white in row 3
ethtab<-table(cnvpheno$allgroup,cnvpheno$ethnicbinary)
ethprop<-prop.table(ethtab,1)
table1a[3,1]<-'% White'
table1a[3,2:6]<-round(100*ethprop,0)

#Add %highbias in row 4
biastab<-table(cnvpheno$allgroup,cnvpheno$bias)
biasprop<-prop.table(biastab,1)
table1a[4,1]<-'% High bias*'
table1a[4,2:6]<-100-round(100*biasprop,0)
table1a[4,2:3]<-'-'
#Add language concerns in row4 - from redcap
#ie twin with parental concern re language

table1a[5,1]<-'% with language concerns**'
langtab<-table(cnvpheno$allgroup,cnvpheno$lang_conc)
langprop<-prop.table(langtab,1)
table1a[5,2:6]<-round(100*langprop[,2],0)
table1a[5,4:6]<-'-'

#Add mean gni in row 6
#Add age in row 2
myaggmean <-aggregate(cnvpheno$global_neurodev,by=list(cnvpheno$allgroup),FUN=mean,na.rm=TRUE)
myaggsd <-aggregate(cnvpheno$global_neurodev,by=list(cnvpheno$allgroup),FUN=sd,na.rm=TRUE)
table1a[6,1]<-'Mean (SD) GNI***'
for (i in 1:5){
table1a[6,(i+1)] <-paste0(round(myaggmean[i,2],1),' (',round(myaggsd[i,2],1),')')
}

write.csv(table1a,'Table 1.csv',row.names=F)

#NB Some manual formatting needed
# Also the asterisks need to be added to foot as table as follows:
#  *SCT cases where trisomy identified during investigations for neurodevelopmental/behavioral disorders
#  **Twin from a pair that was recruited because one or both twins had language problems
#  *** Index of Global Neurodevelopmental Impairment (see Table 2)
```

```{r moretable3}

measures<-c('total_cnvs','total_Kbp','sum_pLi')
for(measure in 1:3){
  thiscol <-which(colnames(cnvpheno)==measures[measure])
for(loop in 1:2){
bytrisomy <- describeBy(cnvpheno[thiscol],cnvpheno$allgroup)
if(loop==2){
  thisrow <-which(cnvpheno$bias==0)
  bytrisomy <- describeBy(cnvpheno[thisrow,thiscol],cnvpheno$allgroup[thisrow])
}
desc.stats<-rbind(data.frame(bytrisomy[[1]])[c(2:5,8:9)],
                  data.frame(bytrisomy[[2]])[c(2:5,8:9)],
                  data.frame(bytrisomy[[3]])[c(2:5,8:9)],
                  data.frame(bytrisomy[[4]])[c(2:5,8:9)],
                  data.frame(bytrisomy[[5]])[c(2:5,8:9)])
rownames(desc.stats)<-levels(cnvpheno$allgroup)
if(loop==1)
{desc.stats.all<-desc.stats}
}
  print(measures[measure])
print('All cases')
print(desc.stats.all)
print('Low bias cases')
print(desc.stats)

bigtable<-data.frame(matrix(NA,nrow=12,ncol=7))
colnames(bigtable)<-c('Karyotype',colnames(desc.stats))
bigtable[1,1]<-paste0('All cases: ',measures[measure])
bigtable[7,1]<-paste0('Low bias: ',measures[measure])
bigtable[2:6,2:7]<-desc.stats.all
bigtable[8:12,2:7]<-desc.stats
bigtable[2:6,1]<-rownames(desc.stats)
bigtable[8:12,1]<-rownames(desc.stats)

if (measure==1){
  bigbigtable <-bigtable
}
if (measure>1){
  bigbigtable <-rbind(bigbigtable,bigtable)
}
}
write.csv(bigbigtable,'Extra_tab3_forAppendix.csv',row.names=F)
```

```{r moretable4}
w<-which(cnvpheno$piq>900) #treat error codes in PIQ as missing data
cnvpheno$piq[w]<-NA
mymat<-cbind(cnvpheno$piq,cnvpheno$langfactor,cnvpheno$global_neurodev)
cor(mymat,use='complete.obs') #just checking correlations between measures

#normally distributed data for langfactor and PIQ
nutab4 <-data.frame(matrix(NA, nrow=10, ncol=5))
colnames(nutab4)<-c('Term','Estimate','SE','t','p')
nutab4[1,1]<-'Linear model, dv = Language factor'

s<-summary(m1 <- lm(langfactor ~ sum_pLi_C + Group + sum_pLi_C:Group,  data=cnvpheno))
nutab4[2:5,2:5]<-round(coef(s),2)
nutab4[6,1]<-'Linear model, dv = PIQ'
s<-summary(m1 <- lm(piq ~ sum_pLi_C + Group + sum_pLi_C:Group,  data=cnvpheno))
nutab4[7:10,2:5]<-round(coef(s),2)
nutab4[2:5,1]<-c('Intercept','Sum pLi','Group','Sum pLI x Group')
nutab4[7:10,1]<-c('Intercept','Sum pLi','Group','Sum pLI x Group')

write.csv(nutab4,'Extended tab4.csv',row.names=F)

```

```{r sessinfo, include=TRUE}
sessionInfo()
```
