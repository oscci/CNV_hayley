---
title: "script_for_AJMG"
author: "DVM Bishop + P Thompson"
date: "18/11/2019"
output: html_document
---

Document based on pre-registered analysis by Mountford et al:
https://osf.io/u2j97

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# many of these functions copied from CNV_for_protocol

require(synthpop) #used to create synthetic dataset
require(tidyverse)
require(stringr)
require(plyr)
require(yarrr)
require(knitr)
library(Hmisc) #for correlation matrix
library(ggplot2)
library(gridExtra)
library(ggpubr)
library(scales)
require(sandwich)
require(msm)
require(lemon) #for glegend
require(MASS)
require(simglm)
require(conflicted) #flags up conflicted functions
require(sandwich)
library(coin)
library(psych)
```

## Read and merge files

Github repository is CNV_Hayley

R project is CNV_Hayley.Rproj on deevybee_repo

Original protocol is CNV_for_protocol.rmd from Jun 16 2018

Manuscript draft is with oscci manuscripts in folder hayley cnv, as Trisomy_CNV_AJMG_v2_DB 

For this OSF version we will read the data from a pre-merged file.
However, the original chunk for doing the merging is retained here, but not run.
(To run it, need to set readoriginal <- 1 at the top of the chunk).

Further information that is only key if you need to set readoriginal to 1:
Data on CNVs now in same folder as R project; original xls file from Dianne, with parental concern variable, is saved as 2 worksheets in csv â€“ one for autosomes and one for X chromosome
all_samples_results_parco.csv
all_samples_results_Xchrom.csv

These need to have name codes changed to match our codes by stripping off DB and making other minor modifications.

Remember to set working directory to source file location

NB famsplangconc coded as 1 if any concern about speech/language in either twin. (Concern may be about the co-twin to the proband) - some of these were coded N/A in Di's file - have updated these manually.


```{r readfiles}
readoriginal <- 2 #set to one if you want to recreate merged cnvpheno file from original files
  #set to 0 to read true data (cnvpheno.csv)
  #set to 2 to read synthetic data (cnv_syn.csv)
makesyn <- 0 #set to 1 to create a synthetic dataset (see end of chunk)

if (readoriginal==1){
cnvdat<-read.csv('all_samples_results_parco_corrected.csv',stringsAsFactors=FALSE)
cnvdatx<-read.csv('all_samples_results_Xchrom.csv',stringsAsFactors=FALSE)

identical(cnvdat$id,cnvdatx$id) #OK - original files were not identical- found mismatch

genderdat<-read.csv('TwinsData_gender.csv')
phenodat<-read.csv('unblinded_pheno_sct_twin.csv',stringsAsFactors=FALSE)
#This file was created using 'geno_pheno_analysis_190215.Rmd' - i.e. main script for Newbury et al paper. In that script, IDs are blinded, but here we need to match up with CNV data, so retain the codes.

#need to strip out correct ID from the cnv files
#first of all remove _rpt from end of name
#also remove DB from start
#using cnvdatx as this seems more accurate, but ultimately should agree with cnvdat



for (i in 1:nrow(cnvdatx)){
  cnvdatx$id[i] <-  str_replace(cnvdatx$id[i],"_rpt", "")
  cnvdatx$id[i] <-  str_replace(cnvdatx$id[i],"DB", "")
    cnvdat$id[i] <-  str_replace(cnvdat$id[i],"_rpt", "")
  cnvdat$id[i] <-  str_replace(cnvdat$id[i],"DB", "")
}

#for SCTs, just retain first 3 digits
myrows<-which(cnvdatx$Group != 'twin')

cnvdatx$id[myrows]<-str_sub(cnvdatx$id[myrows],1,3)
cnvdat$id[myrows]<-str_sub(cnvdatx$id[myrows],1,3)
#NB these ids are characters, so need to alter phenodat,where id is numeric
#Need to add leading zeroes, so, e.g. 1 becomes 001

phenodat$id<-as.character(phenodat$record_id)
w<-which(as.numeric(phenodat$record_id)<10)
phenodat$id[w]<-paste0('0',phenodat$id[w])
w<-which(as.numeric(phenodat$record_id)<100)
phenodat$id[w]<-paste0('0',phenodat$id[w])

#order all files by id
genderdat <- genderdat[order(genderdat$record_id),] 
phenodat <- phenodat[order(phenodat$id),] 
cnvdat <- cnvdat[order(cnvdat$id),] 
cnvdatx <- cnvdatx[order(cnvdatx$id),] 
#align files and bolt together

#Just check we do have same cases in same rows
for(i in 1:nrow(cnvdat)){
  if(cnvdat$id[i] != cnvdatx$id[i]){
    print(cnvdat$id[i])
  }
  }



w<-which(phenodat$id %in% cnvdatx$id)

cnvpheno<-cbind(phenodat[w,2:44],cnvdat[,2:11],cnvdatx[,2:8])

cnvpheno$female<-0
w4<-which(cnvpheno$trisomy==1)
cnvpheno$female[w4]<-1

w3<-which(cnvpheno$Group=='twin')
w2<-which(genderdat$record_id %in% cnvpheno$id) #twins only!

cnvpheno$female[w3]<-genderdat$female[w2] #twins who are in cnvpheno assigned gender from genderdat

cnvpheno$groupfem<-paste0(cnvpheno$Group,cnvpheno$female)

#Do some renaming of cols
for (i in 54:60){
  colnames(cnvpheno)[i]<-paste0(colnames(cnvpheno)[i],'X')
}
cnvpheno$is.trisomy <-1
w<-which(cnvpheno$Group=='twin')
cnvpheno$is.trisomy[w]<-0 

#code bias group
cnvpheno$bias<-cnvpheno$famsplangconc #default from twin code for family bias

w<-which(cnvpheno$Group !='twin')
cnvpheno$bias[w]<-0 #default no bias for trisomies
w<-c(which(cnvpheno$why_tested==2),which(cnvpheno$why_tested==3))
cnvpheno$bias[w]<-1

write.csv(cnvpheno,'cnvpheno.csv',row.names=FALSE) #saved copy of file

if(makesyn==1){
#now create synthetic dataset to preserve confidentiality
mysyn<-syn(cnvpheno[,c(42,44:52,54:60,62:64)])$syn #create synthetic dataset
write.csv(mysyn,'cnv_syn_OSF.csv',row.names=FALSE)
}
}

```

We now have a file with the phenotype and genotype data together.  
First thing that is needed is Table 1, showing Ns in relation to ascertainment bias.

```{r table1}


if(readoriginal==0){
  cnvpheno <- read.csv('cnvpheno.csv',stringsAsFactors=FALSE)
}
if(readoriginal==2 ){ #read synthesised data}
  cnvpheno <- read.csv('cnv_syn.csv',stringsAsFactors=FALSE)
}
mytab<- table(cnvpheno$groupfem,cnvpheno$bias)
mytab

```

The derivation of the global neurodevelopmental index is now provided in the paper in Table 2.
(In this version we use original scores, so high score represents poor functioning. 




```{r for.Fig1, echo=FALSE}
#-----------------------------------------------------------------------------#


# Scatter plot with marginal histograms 
# Have taken log for kBp to aid visualisation
# Used colour to depict twin/SCT and fill to depict low bias

# Create factor variables for group and bias
cnvpheno$trisomy<-factor(cnvpheno$is.trisomy)
levels(cnvpheno$trisomy) <- c('Comparison','Trisomy')

cnvpheno$bias_fac<-as.factor(cnvpheno$bias)
shapelist<-c(19,1)  
#This variable allows mapping of shape and fill as follows:
# bias = unfilled circle
# no Bias = filled circle

levels(cnvpheno$bias_fac) <- c('Low bias' ,'High Bias')
cnvpheno$jitter_cnv<-jitter(cnvpheno$total_cnvs)+.2 #add .2 to avoid negative value
p1 <- ggplot(cnvpheno,aes(y=log(total_Kbp+1),x=jitter_cnv,colour=trisomy,shape=bias_fac))+
  scale_shape_manual(values=shapelist)+
   scale_color_manual(values=c('gray21','red'))+
  geom_point()+
  scale_x_continuous(expand=c(0.02,0)) +
  scale_y_continuous(expand=c(0.02,0)) +
 labs(x = "N CNVs",y="Total CNV span (log Kb)")+
  theme_bw() + guides(row = guide_legend(nrow=2)) +
  theme(legend.position=c(1,1.25),plot.margin=unit(c(1,1,1,1),"points"),legend.title = element_blank(),legend.text = element_text(size = 8),axis.title = element_text(size = 10),legend.box = "horizontal",
        legend.background = element_rect(fill="grey",colour = "black"))

theme0 <- function(...) theme( legend.position = "none",
                               panel.background = element_blank(),
                               panel.grid.major = element_blank(),
                               panel.grid.minor = element_blank(),
                               panel.margin = unit(0,"null"),
                               axis.ticks = element_blank(),
                               axis.text.x = element_blank(),
                               axis.text.y = element_blank(),
                               axis.title.x = element_blank(),
                               axis.title.y = element_blank(),
                               axis.ticks.length = unit(0,"null"),
                               axis.ticks.margin = unit(0,"null"),
                               panel.border=element_rect(color=NA),...)

p2 <- ggplot(cnvpheno,aes(x=total_cnvs,colour=factor(trisomy),fill=factor(trisomy))) + 
  geom_density(alpha=0.5) + 
  scale_color_manual(values=c('gray21','red'))+
  scale_fill_manual(values=c('gray21','red'))+
  scale_x_continuous(breaks=NULL,expand=c(0.00,0)) +
  scale_y_continuous(breaks=NULL,expand=c(0.00,0)) +
  theme_bw() +
  theme0(plot.margin = unit(c(0,0,0,2),"lines")) 

p3 <- ggplot(cnvpheno,aes(x=log(total_Kbp+1),colour=factor(trisomy),fill=factor(trisomy))) + 
  geom_density(alpha=0.5) + 
  scale_color_manual(values=c('gray21','red'))+
   scale_fill_manual(values=c('gray21','red'))+
  coord_flip()  + 
  scale_x_continuous(labels = NULL,breaks=NULL,expand=c(0.02,0)) +
  scale_y_continuous(labels = NULL,breaks=NULL,expand=c(0.00,0)) +
  theme_bw() +
  theme0(plot.margin = unit(c(0,0,1.75,0),"lines"))

#assemble the 3 plots in a grid

 g1<-grid.arrange(arrangeGrob(p2,ncol=2,widths=c(3,1)),
             arrangeGrob(p1,p3,ncol=2,widths=c(3,1)),
             heights=c(1,3))
g1
 #ggsave preserves appearance of plot. 
ggsave("CNV_fig1.png",plot=g1,device = 'png',dpi = 600,width=4.5,height=4,units = 'in')

# The figure we've just created is displayed in the Markdown document

##############################################################################
```

![Figure 1](CNV_fig1.png)

```{r for.Fig2, echo=FALSE}
#-----------------------------------------------------------------------------#

# Figure 2 shows PLI score with global neurodev scale
# Otherwise same as figure 1
# Scatter plot with marginal histograms 
# Used colour to depict twin/SCT and fill to depict bias - use settings from fig 1

cnvpheno$neurodev_jittered <- jitter(cnvpheno$global_neurodev)+.2
p1 <- ggplot(cnvpheno,aes(x=sum_pLi,y=neurodev_jittered,colour=trisomy,shape=bias_fac))+
  scale_shape_manual(values=shapelist)+
   scale_color_manual(values=c('gray21','red'))+
  geom_point()+
  scale_x_continuous(expand=c(0.02,0)) +
  scale_y_continuous(expand=c(0.02,0)) +
 labs(x = "Total pLI (all CNVs)",y="Global neurodev. impairment")+
  theme_bw() + guides(row = guide_legend(nrow=2)) +
  theme(legend.position=c(1,1.25),plot.margin=unit(c(1,1,1,1),"points"),legend.title = element_blank(),legend.text = element_text(size = 8),axis.title = element_text(size = 10),legend.box = "horizontal",
        legend.background = element_rect(fill="grey",colour = "black"))

theme0 <- function(...) theme( legend.position = "none",
                               panel.background = element_blank(),
                               panel.grid.major = element_blank(),
                               panel.grid.minor = element_blank(),
                               panel.margin = unit(0,"null"),
                               axis.ticks = element_blank(),
                               axis.text.x = element_blank(),
                               axis.text.y = element_blank(),
                               axis.title.x = element_blank(),
                               axis.title.y = element_blank(),
                               axis.ticks.length = unit(0,"null"),
                               axis.ticks.margin = unit(0,"null"),
                               panel.border=element_rect(color=NA),...)

p2 <- ggplot(cnvpheno,aes(x=sum_pLi,colour=factor(trisomy),fill=factor(trisomy))) + 
  geom_density(alpha=0.5) + 
  scale_color_manual(values=c('gray21','red'))+
  scale_fill_manual(values=c('gray21','red'))+
  scale_x_continuous(breaks=NULL,expand=c(0.00,0)) +
  scale_y_continuous(breaks=NULL,expand=c(0.00,0)) +
  theme_bw() +
  theme0(plot.margin = unit(c(0,0,0,2),"lines")) 

p3 <- ggplot(cnvpheno,aes(x=global_neurodev,colour=factor(trisomy),fill=factor(trisomy))) + 
  geom_density(alpha=0.5) + 
  scale_color_manual(values=c('gray21','red'))+
   scale_fill_manual(values=c('gray21','red'))+
  coord_flip()  + 
  scale_x_continuous(labels = NULL,breaks=NULL,expand=c(0.02,0)) +
  scale_y_continuous(labels = NULL,breaks=NULL,expand=c(0.00,0)) +
  theme_bw() +
  theme0(plot.margin = unit(c(0,0,1.75,0),"lines"))



g2<- grid.arrange(arrangeGrob(p2,ncol=2,widths=c(3,1)),
             arrangeGrob(p1,p3,ncol=2,widths=c(3,1)),
             heights=c(1,3))

ggsave("CNV_fig2.png",plot=g2,device = 'png',dpi = 600,width=4.5,height=4,units = 'in')



##############################################################################
```
![Figure 2](CNV_fig2.png)



Next we consider how well the different measures differentiate between the groups. Because the data is non-normal, a Wilcoxon rank sum test is used. In a preliminary analysis, we analyse each dependent measure separately.

```{r comparegp,echo=FALSE}
##############################################################################

#Multiple testing: Wilcoxon sum rank test, one-tailed
dowilcox <- function(mydf){
BF_correct_alpha<-0.05/3
w1<-wilcox.test(total_cnvs~is.trisomy,data=mydf,alternative=c("less"),conf.int=TRUE)
w2<-wilcox.test(total_Kbp~is.trisomy,data=mydf,alternative=c("less"),conf.int=TRUE)
w3<-wilcox.test(sum_pLi~is.trisomy,data=mydf,alternative=c("less"),conf.int=TRUE)


#Corrections for multiple testing

# Given correlations between the CNV measures, the Benjamini-Yekutieli (BY) correction is applied. We see that the pattern of significance among the tests remains unchanged.

##
pvals<-round(c(w1$p.value,w2$p.value,w3$p.value),3)
BY = p.adjust(pvals, "BY")
res = cbind(pvals, BY=round(BY, 3))
colnames(res)<-c("Uncorrected","Benjamini-Y")
rownames(res)<-c('Total CNVs','Total Kbp',"sum pLi")
return(res)}

```

Hayley had done analysis using permutation analysis in PLINK. We can achieve the same results in R. N.B. 
This was not the pre-registered analysis, though it could be argued that it is a reasonable one to do. The results do differ from Wilcoxon - we think this is to do with how the different methods handle ties.

Here is a function to do that

```{r permtest}
#Multiple testing: permutation test, one-tailed
doperm <- function(mydf){
BF_correct_alpha<-0.05/3

p1<-coin::pvalue(oneway_test(total_cnvs~is.trisomy,data=mydf, alternative="less", 
                   distribution=approximate(nresample=9999)))
p2<-coin::pvalue(oneway_test(total_Kbp~is.trisomy,data=mydf, alternative="less", 
                   distribution=approximate(nresample=9999)))
p3<-coin::pvalue(oneway_test(sum_pLi~is.trisomy,data=mydf, alternative="less", 
                   distribution=approximate(nresample=9999)))

pvals<-round(c(p1[1],p2[1],p3[1]),3)
BY = p.adjust(pvals, "BY")
res = cbind(pvals, BY=round(BY, 3))
colnames(res)<-c("Uncorrected","Benjamini-Y")
rownames(res)<-c('Total CNVs','Total Kbp',"sum pLi")
return(res)}

```

```{r makeresultstabs}

cnvpheno$is.trisomy<-as.factor(cnvpheno$is.trisomy)
# Divide data into 2 sets; with and without bias
w<-which(cnvpheno$bias==1)
bias.set<-cnvpheno[w,]
nobias.set<-cnvpheno[-w,]

resw1 <-dowilcox(cnvpheno)
knitr::kable(resw1, caption='Wilcoxon: All cases')

resw2 <-dowilcox(nobias.set)
knitr::kable(resw2, caption='Wilcoxon: Low bias cases')

resp1<-doperm(cnvpheno)
knitr::kable(resp1, caption='Permutation: All cases')

resp2<-doperm(nobias.set)
knitr::kable(resp2, caption='Permutation: Low bias cases')

print('All cases')
by_group<-cnvpheno %>% group_by(is.trisomy)
groupmeans<-dplyr::summarise(by_group,
  mean_cnvs = round(mean(total_cnvs),2),
   sd_cnvs = round(sd(total_cnvs),2),
    mean_Kbp = round(mean(total_Kbp),1),
   sd_Kbp = round(sd(total_Kbp),1),
  mean_pLi = round(mean(sum_pLi),3),
  sd_pLi = round(sd(sum_pLi),3)
)
groupmeans

print('Low Bias')
by_group2<-nobias.set %>% group_by(is.trisomy)
groupmeans2<-dplyr::summarise(by_group2,
  mean_cnvs = round(mean(total_cnvs),2),
   sd_cnvs = round(sd(total_cnvs),2),
    mean_Kbp = round(mean(total_Kbp),1),
   sd_Kbp = round(sd(total_Kbp),1),
  mean_pLi = round(mean(sum_pLi),3),
  sd_pLi = round(sd(sum_pLi),3)
)
groupmeans2

```

```{r makemaintable}
maintab <- data.frame(matrix(NA,nrow=9,ncol=6))
colnames(maintab)<- c('Measure','SCT','Comparison','.','p-values','..')
maintab[,1]<-c('N Whole sample','CNV per individual','CNV total span (Kb)','Total pLI score','.','N low bias subset','CNV per individual','CNV total span (Kb)','Total pLI score')

#can take Ns from original Table 1 (mytab)
Nsct<-sum(mytab[3:5,1:2])
Ntwin<-sum(mytab[1:2,1:2])
Nsct.x<-sum(mytab[3:5,1])
Ntwin.x<-sum(mytab[1:2,1])

maintab[1,2]<-Nsct
maintab[1,3]<-Ntwin
maintab[6,2]<-Nsct.x
maintab[6,3]<-Ntwin.x

maintab[1,4]<-'Wilcoxon'
maintab[1,5]<-'Permutation'
maintab[1,6]<-'BY corrected'

maintab[2,2]<-paste0(groupmeans[2,2],' (',groupmeans[2,3],')')
maintab[2,3]<-paste0(groupmeans[1,2],' (',groupmeans[1,3],')')

maintab[3,2]<-paste0(groupmeans[2,4],' (',groupmeans[2,5],')')
maintab[3,3]<-paste0(groupmeans[1,4],' (',groupmeans[1,5],')')

maintab[4,2]<-paste0(groupmeans[2,6],' (',groupmeans[2,7],')')
maintab[4,3]<-paste0(groupmeans[1,6],' (',groupmeans[1,7],')')

maintab[7,2]<-paste0(groupmeans2[2,2],' (',groupmeans2[2,3],')')
maintab[7,3]<-paste0(groupmeans2[1,2],' (',groupmeans2[1,3],')')

maintab[8,2]<-paste0(groupmeans2[2,4],' (',groupmeans2[2,5],')')
maintab[8,3]<-paste0(groupmeans2[1,4],' (',groupmeans2[1,5],')')

maintab[9,2]<-paste0(groupmeans2[2,6],' (',groupmeans2[2,7],')')
maintab[9,3]<-paste0(groupmeans2[1,6],' (',groupmeans2[1,7],')')

maintab[2:4,4]<-resw1[1:3,1]
maintab[7:9,4]<-resw2[1:3,1]
maintab[2:4,5:6]<-resp1[1:3,1:2]
maintab[7:9,5:6]<-resp2[1:3,1:2]

write.csv(maintab,'Table3.csv',row.names=FALSE)

#This table can be opened in Word.
# Needs editing (change comma to tab, remove quotes and NA, but can then do convert text to table, and minor formatting)
```


## Phenotype analysis
We have three possible phenotypes that were used by Newbury et al (2018). We decided *a priori* that the measure of global neurodevelopmental impairment is optimal, because previous research on CNVs implicates more severe conditions such as ASD and intellectual disability, which are captured by this measure.




## Poisson regression
Poisson regression is the optimal method, as the dependent variable is a count. This will naturally allow for the lower bound of zero.

Reference for analysis: https://stats.idre.ucla.edu/r/dae/poisson-regression/
```{r poisson, echo=TRUE}
#-----------------------------------------------------------------------------#
summary(m1 <- glm(global_neurodev ~ sum_pLi + is.trisomy + sum_pLi:is.trisomy, family="poisson", data=cnvpheno))

#check the assumption that mean and variance ar roughly equal. If not, we can use robust estimates. I think this will make little difference in our case but included for completeness.

cov.m1 <- vcovHC(m1, type="HC0")
std.err <- sqrt(diag(cov.m1))
r.est <- cbind(Estimate= coef(m1), "Robust SE" = std.err,
               "Pr(>|z|)" = 2 * pnorm(abs(coef(m1)/std.err), lower.tail=FALSE),
               LL = coef(m1) - 1.96 * std.err,
               UL = coef(m1) + 1.96 * std.err)

r.est

#test the effect of dropping is.trisomy. We anticipate that this will be impair model fit.
m2 <- update(m1, . ~ . - is.trisomy)
## test model differences with chi square test
anova(m2, m1, test="Chisq")

#-----------------------------------------------------------------------------#
```
